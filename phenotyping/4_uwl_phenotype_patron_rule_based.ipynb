{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020e8dc6",
   "metadata": {},
   "source": [
    "# Algorithm for Unexpected Weight Loss phenotype: rule-based\n",
    "\n",
    "12 July 2023\n",
    "\n",
    "Updated 23 February 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Description\n",
    "\n",
    "Code that takes tables from Patron and creates a cohort of patients who likely have Unexpected Weight Loss. \n",
    "\n",
    "## Methodology\n",
    "- Transform each of the tables to clean datetimes and create flags for different types of 'weight-related' events: weight, weight loss, weight loss medication, weight loss inquiry\n",
    "- Create an event log by concatenating all the tables\n",
    "- Create uwl_flag for candiate patients based on boolean condition of flags\n",
    "- Use rule-based classification algorithm to further filter the candidates to remove those that are unlikely to be UWL\n",
    "- Create time-period flags: index date; time periods from index date; cancer diagnosis date\n",
    "- Calculate the statistics of numbers of UWL patients and proportion that are diagnosed with cancer within six months of index date.\n",
    "\n",
    "## Patient flow\n",
    "- Create the subset of patients at each step in the creation of the cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfc3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7c86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885d985",
   "metadata": {},
   "source": [
    "## 1. Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b066422",
   "metadata": {},
   "source": [
    "### Patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da4236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patron source folders\n",
    "source_folder1_patron = \"M:/Working/AL/Projects/weight_loss/outputs/patron_data_extracts\"\n",
    "source_folder2_patron = \"M:/Working/AL/Projects/weight_loss/outputs\"\n",
    "source_folder3_patron = \"M:/Working/DataAnalysis/CleanAndStructure/DataFiles\"\n",
    "source_folder4_patron = \"M:/Working/DataAnalysis/RCOLD/DataFiles\"\n",
    "\n",
    "# patron files\n",
    "filename_encounter_patron = \"patron_encounters_310123.parquet\"\n",
    "filename_diagnosis_patron = \"patron_condition_history_310123.parquet\"\n",
    "filename_prescription_patron = \"patron_prescriptions_300123.parquet\"\n",
    "filename_patient_patron = \"patron_patient_300123.parquet\"\n",
    "filename_pathology_patron = \"pathology_patron_10_results_cleaned_BN_ranges_270423.parquet\"\n",
    "filename_hwbmi_patron = \"patron_height_weight_observations_cleaned_300123.parquet\"\n",
    "filename_pathology_patron = \"pathology_patron_10_results_cleaned_Vic_ranges_120523.parquet\"\n",
    "\n",
    "# VAED Procedures\n",
    "filename_vaed_proc = 'VAED_AllProceduresLong_202112.parquet'\n",
    "filename_vaed_proc_ah = 'VAED_AllProceduresLong_AH_202112.parquet'\n",
    "\n",
    "filename_cancer = 'VAED_Cancers_coded.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5414d",
   "metadata": {},
   "source": [
    "## 2. Regular expressions and inclusion / exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cc182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight-related terms\n",
    "weight_spellings = [\"WEIGHT\", \"WIEGHT\", \" WT\", \"WT \", 'WEIGT', 'WEGHT', 'WEIGH ', '^LOW$',\n",
    "                    'WEIGTH', 'WGT', 'WGHT', 'WHT ', '[0-9\\s]+KG', 'CACHEXI', 'BMI']\n",
    "\n",
    "initial_regex = r\"|\".join(weight_spellings)\n",
    "\n",
    "# terms that relate to weight loss\n",
    "loss_terms = ['LOSS', 'LOSSS', 'LOST', 'DECREASE', 'LOSING', 'LOSSING', 'LOW', 'LAST', 'CACHEXI']\n",
    "loss_regex = r\"|\".join(loss_terms)\n",
    "\n",
    "# exclusion terms that relate to a weight loss program or other enquiry\n",
    "exclusion_terms = [\"PROGRAM\", \"COUNSELLING\", \"MANAGEMENT\", \n",
    "                     \"ADVICE\", \"CLINIC\", \"DISCUSSION\",\n",
    "                     \"REGIME\", \"MANAGMENT\", \"JENNY CRAIG\", \"CONSULTATION\", \"MEDICATION\"]\n",
    "\n",
    "exclusion_regex = r\"|\".join(exclusion_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bc2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_encounters = [\"usi\", \n",
    "                      \"dte\", \n",
    "                      \"reason\", \n",
    "                      \"weight_flag\", \n",
    "                      \"weightloss_flag\", \n",
    "                      \"weightloss_inquiry_flag\", \n",
    "                      \"event_type\"]\n",
    "\n",
    "columns_diagnoses = [\"usi\", \n",
    "                     \"dte\", \n",
    "                     \"reason\", \n",
    "                     \"weight_flag\", \n",
    "                     \"weightloss_flag\", \n",
    "                     \"weightloss_inquiry_flag\", \n",
    "                     \"event_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f430a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many patients with the following\n",
    "bariatric_regex = r'BARIATRIC|LAP BAND|GASTRIC BAND|GASTRIC SLEEVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2987da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prescription_cols_nps = ['patientid', \n",
    "                     'usi',\n",
    "                     'firstprescrip_dte', \n",
    "                     'lastprescrip_dte',\n",
    "                     'medicine_active_ingredient', \n",
    "                     'prescription_reason']\n",
    "\n",
    "prescription_cols_nps = ['usi',  \n",
    "                     'dte',  \n",
    "                     'value', \n",
    "                     'value2', \n",
    "                     'event_type', \n",
    "                     'weightloss_med_flag']\n",
    "\n",
    "medicine_wtloss_terms = ['PHENTERMINE', \n",
    "                         'SIBURTRAMINE', \n",
    "                         'ORLISTAT', \n",
    "                         'LIRAGLUTIDE', \n",
    "                         'TOPIRAMATE', \n",
    "                         'SEMAGLUTIDE', \n",
    "                         'SIBUTRAMINE', \n",
    "                         'DUROMINE']\n",
    "\n",
    "# create regular expression to extract weight loss medications\n",
    "medicine_wtloss_regex = r'|'.join(medicine_wtloss_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d196a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covers: replacing inequalities, removing non-numeric strings\n",
    "weird_values_replace = {r'>\\\\S\\\\([0-9.]+)': '\\g<1>',\n",
    "                        r'>\\s?([0-9.]+)': '\\g<1>',\n",
    "                        r'>\\s*\\^([0-9.]+)': '\\g<1>',\n",
    "                        r'>\\^([0-9.]+)': '\\g<1>',\n",
    "                        r'>\\s*([0-9.]+)': '\\g<1>',\n",
    "                        r'>\\s?\\^([0-9.]+)': '\\g<1>',\n",
    "                        r'<\\\\S\\\\([0-9.]+)': '\\g<1>',\n",
    "                        r'<\\s?([0-9.]+)': '\\g<1>',\n",
    "                        r'<\\s*\\^([0-9.]+)': '\\g<1>',\n",
    "                        r'<\\^([0-9.]+)': '\\g<1>',\n",
    "                        r'<\\s*([0-9.]+)': '\\g<1>',\n",
    "                        r'<\\s?\\^([0-9.]+)': '\\g<1>',\n",
    "                        r'^([0-9]+)\\+$': '\\g<1>',\n",
    "                        r'^([0-9.]+)\\+$': '\\g<1>',\n",
    "                        r'^([0-9]+)\\-$': '\\g<1>',\n",
    "                        r'^([0-9.]+)\\-$': '\\g<1>',\n",
    "                        r'^([0-9]+)\\`$': '\\g<1>',\n",
    "                        r'^([0-9.]+)\\`$': '\\g<1>',\n",
    "                        r'^([0-9\\.]+)[A-Za-z\\.\\s]+$': '\\g<1>', \n",
    "                        r'^[0]*\\,([0-9]{2})$': '\\g<1>',\n",
    "                        r'^[^0-9\\.]+$': '', \n",
    "                        r'([0-9\\.]{3}).+': '\\g<1>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839a7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols_observations = {'observation_dte': 'dte', \n",
    "                            'observation_type': 'event_subtype', \n",
    "                            'observation_value_cleaned': 'value'}\n",
    "\n",
    "select_cols_observations = ['usi', 'dte', 'value', 'event_type', 'event_subtype']\n",
    "\n",
    "dte_cols_observations = ['observation_dte']\n",
    "\n",
    "text_cols_observations = ['observation_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65032f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols_prescription = {'prescription_reason': 'value', \n",
    "                            'medicine_active_ingredient': 'value2', \n",
    "                            'medicine_name': 'value3', \n",
    "                            'firstprescrip_dte': 'dte'}\n",
    "\n",
    "select_cols_prescription = ['usi', 'dte', 'value', 'value2', 'event_type', 'weightloss_med_flag']\n",
    "\n",
    "dte_cols_prescription = ['firstprescrip_dte']\n",
    "\n",
    "text_cols_prescription = ['prescription_reason', 'medicine_active_ingredient', 'medicine_name']\n",
    "\n",
    "flag_cols_prescription = {'weightloss_med_flag': lambda df_: df_['medicine_active_ingredient'].str.contains(medicine_wtloss_regex, na=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a5e78",
   "metadata": {},
   "source": [
    "### Patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289b8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_cols_prescription = {'medication_active_ingredient': 'medicine_active_ingredient', \n",
    "                              'dte': 'firstprescrip_dte'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e85395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols_pathology = {'result_dte': 'dte', \n",
    "                         'result_name_standard': 'event_subtype', \n",
    "                         'result_value_cleaned': 'value', \n",
    "                         'units_standard': 'value2', \n",
    "                         'value_range': 'value3'}\n",
    "\n",
    "select_cols_pathology = ['usi', 'dte', 'event_type', 'event_subtype', 'value', 'value2', 'value3']\n",
    "\n",
    "flags_col_pathology = None\n",
    "\n",
    "dte_cols_pathology = ['result_dte']\n",
    "\n",
    "text_cols_pathology = ['result_name_standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b47ae70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_cols_encounters = {'weight_flag': lambda df_: df_.encounter_reason.str.contains(initial_regex, na=False), \n",
    "                        'weightloss_flag': lambda df_: df_.weight_flag & df_.encounter_reason.str.contains(loss_regex, na=False), \n",
    "                        'weightloss_inquiry_flag': lambda df_: df_.weightloss_flag & df_.encounter_reason.str.contains(exclusion_regex, na=False),\n",
    "                        'bariatric_surgery_flag': lambda df_: df_.encounter_reason.str.contains(bariatric_regex, na=False)}\n",
    "\n",
    "rename_cols_encounters = {'visit_dte': 'dte', \n",
    "                          'encounter_reason': 'value'}\n",
    "\n",
    "select_cols_encounters = ['usi', \n",
    "                          'dte', \n",
    "                          'event_type', \n",
    "                          'value', \n",
    "                          'weight_flag', \n",
    "                          'weightloss_flag', \n",
    "                          'weightloss_inquiry_flag', \n",
    "                          'bariatric_surgery_flag']\n",
    "\n",
    "dte_cols_encounters = ['visit_dte']\n",
    "\n",
    "text_cols_encounters = ['encounter_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa55169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_cols_diagnoses = {'weight_flag': lambda df_: df_.diagnosis_reason.str.contains(initial_regex, na=False), \n",
    "                       'weightloss_flag': lambda df_: df_.weight_flag & df_.diagnosis_reason.str.contains(loss_regex, na=False), \n",
    "                       'weightloss_inquiry_flag': lambda df_: df_.weightloss_flag & df_.diagnosis_reason.str.contains(exclusion_regex, na=False), \n",
    "                       'bariatric_surgery_flag': lambda df_: df_.diagnosis_reason.str.contains(bariatric_regex, na=False)}\n",
    "\n",
    "rename_cols_diagnoses = {'diagnosis_dte': 'dte', \n",
    "                         'diagnosis_reason': 'value'}\n",
    "\n",
    "select_cols_diagnoses = ['usi', \n",
    "                         'dte', \n",
    "                         'event_type', \n",
    "                         'value', \n",
    "                         'weight_flag', \n",
    "                         'weightloss_flag', \n",
    "                         'weightloss_inquiry_flag', \n",
    "                         'bariatric_surgery_flag']\n",
    "\n",
    "dte_cols_diagnoses = ['diagnosis_dte']\n",
    "\n",
    "text_cols_diagnoses = ['diagnosis_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1564882",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_formats = ['%Y-%m-%d', \n",
    "              '%d/%m/%Y',\n",
    "              '%d/%m/%y', \n",
    "              '%d.%m.%Y', \n",
    "              '%d.%m.%y', \n",
    "              '%d %m %y', \n",
    "              '%d/%m%Y', \n",
    "              '%d%m%Y', \n",
    "              '%d.%m.%Y', \n",
    "              '%d.%m/%Y', \n",
    "              '%d %m %Y', \n",
    "              '%d-%m-%Y']\n",
    "\n",
    "def format_dates(dates, date_formats=['%d/%m/%Y']):\n",
    "    \"\"\"\n",
    "    Standardize a pd.Series of datetimes based on a set of specified datetime formats\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    \n",
    "    dates (pd.Series): input of datetime values to convert\n",
    "    formats (list of str): strings that specify all the possible formats that dates appear in\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dates_standard (pd.Series): standardized datetime values\n",
    "    \"\"\"\n",
    "    dates_standard = pd.to_datetime(dates, format=date_formats[0], errors='coerce')\n",
    "    \n",
    "    for n in range(1, len(date_formats)):\n",
    "        dates_standard = dates_standard.fillna(pd.to_datetime(dates, format=dt_formats[n], errors='coerce'))\n",
    "    \n",
    "    return dates_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992ca18",
   "metadata": {},
   "source": [
    "## 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff29811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index_case_label(df, \n",
    "                         patientid='usi', \n",
    "                         date='date', \n",
    "                         case='uwl_flag'):\n",
    "    \"\"\"\n",
    "    Add a new column for the index date for each of the patients.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    df (pd.DataFrame): the input dataframe\n",
    "    patientid (str): the column name of the patientid field\n",
    "    date (str): the column name of the date field\n",
    "    csae (str): the column name of the case field\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    df (pd.DataFrame): dataframe with the index date column added\n",
    "    \"\"\"\n",
    "    df = df.copy().assign(index_case=False)\n",
    "    df.loc[df.groupby(patientid)[case].idxmax().values, 'index_case'] = True\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa5c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_within_time_period(df, \n",
    "                              patientid='usi', \n",
    "                              date='date',\n",
    "                              index_date='index_case', \n",
    "                              time_period=(0, 31), \n",
    "                              time_period_label='one_month'):\n",
    "    \"\"\"\n",
    "    Create a column that, for each patient, flags all events within a given \n",
    "    time period\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    df (pd.DataFrame): input dataframe\n",
    "    patientid (str): column name field patient id field\n",
    "    date (str): column name for date field\n",
    "    index_date (str): column name of index date\n",
    "    time_period (tuple): the time period (in days)\n",
    "    time_period_label (str): label of the time period\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    results = (\n",
    "        df\n",
    "        .groupby(patientid)\n",
    "        .apply(lambda df_: df_[date] - df_[df_[index_date] == True][date].values[0])\n",
    "        .dt.days.between(*time_period)\n",
    "        .reset_index()\n",
    "        .loc[:, date]\n",
    "    )\n",
    "    \n",
    "    df = df.assign(**{f'{time_period_label}': results})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb925529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent_weight_change(df):\n",
    "    \"\"\"\n",
    "    Calculate the weight change up until the index date\n",
    "    If there is no weight recording at the index date then\n",
    "    returns -1000\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    df (pd.DataFrame): event log for a given patient\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    weight_change (float): difference in weight between the index date and\n",
    "                           previous weight observation\n",
    "    \"\"\"\n",
    "    index_date = df.query('index_case == 1')['dte'].values[0]\n",
    "    \n",
    "    weights_previous = (\n",
    "        df\n",
    "        .query(f'dte <= \"{index_date}\"')\n",
    "        .query('event_subtype == \"WEIGHT\"')\n",
    "    )\n",
    "    \n",
    "    # check that there is a weight recording at the index date\n",
    "    if weights_previous.query('at_index_date == True').shape[0] == 0:\n",
    "        return -1000\n",
    "    else:\n",
    "        # check that there are at least two weight recordings to calculate\n",
    "        # difference\n",
    "        if weights_previous.shape[0] >= 2:\n",
    "            weights = weights_previous['value'].astype(float).values\n",
    "            weight_change = weights[-1] - weights[-2]\n",
    "            return weight_change\n",
    "        else:\n",
    "            return -1000\n",
    "        \n",
    "        \n",
    "def weight_increase(df):\n",
    "    \"\"\"\n",
    "    Create flag for whether there is a weight increase up to\n",
    "    index date\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    df (pd.DataFrame): input event log for a single patient\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    df (pd.DataFrame): dataframe with flag added\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.assign(weight_increase=lambda df_: \n",
    "                   True if \n",
    "                   recent_weight_change(df_) > 0 \n",
    "                   else \n",
    "                   False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "041e55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_table_standard(events, \n",
    "                             rename_cols, \n",
    "                             select_cols, \n",
    "                             flag_cols,\n",
    "                             dte_cols=['visit_dte'], \n",
    "                             main_date_col = 'dte',\n",
    "                             text_cols=['encounter_reason'], \n",
    "                             event_name='encounter'):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    Transform a given input table (such as encounters, diagnoses, prescriptions)\n",
    "    so that datetime values are processed, basic cleaning has been done to text fields\n",
    "    columns have been renamed appropriated and subsetted and additional columns added\n",
    "    to flag relevant events\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    events (pd.DataFrame): dataframe containing a given set of events\n",
    "    rename_cols (dict): mapping from old column to new column names\n",
    "    select_cols (list of str): columns to select from the dataframe\n",
    "    flag_cols (dict): mapping of new column names to transformations that define flags \n",
    "    dte_cols (list of str): datetime columns\n",
    "    text_cols (list of str): columns that contain text\n",
    "    event_name (str): event name to describe this set of events\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    events_new (pd.DataFrame): transformed dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # acceptable formats for datetime values\n",
    "    dte_pattern1 = '\\d{1,2}\\/\\d{1,2}\\/\\d{4}'\n",
    "    dte_pattern2 = '\\d{4}-\\d{2}-\\d{2}.*'\n",
    "    dte_pattern3 = '\\d{2}\\.\\d{2}\\.\\d{4}'\n",
    "    dte_pattern4 = '\\d{1,2}[\\s\\.\\/]\\d{1,2}[\\s\\.\\/]\\d{2}'\n",
    "\n",
    "    dte_pattern_all = f'^(?!({dte_pattern1}|{dte_pattern2}|{dte_pattern3}|{dte_pattern4}))'\n",
    "\n",
    "    # clean the datetime variables\n",
    "    dt_clean = dict(\n",
    "        zip(\n",
    "            dte_cols, \n",
    "            [lambda df_, dte_col=dte_col: df_[dte_col].astype(str).fillna('').str.replace(dte_pattern_all, '', regex=True) for dte_col in dte_cols]\n",
    "        )        \n",
    "    )\n",
    "    \n",
    "    # standardize the datetime variables\n",
    "    dt_changes = dict(\n",
    "        zip(\n",
    "            dte_cols, \n",
    "            [lambda df_, dte_col=dte_col: format_dates(df_[dte_col], dt_formats) for dte_col in dte_cols]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # standardize the text variables\n",
    "    text_changes = dict(\n",
    "        zip(\n",
    "            text_cols, \n",
    "            [lambda df_, text_col=text_col: df_[text_col].str.upper().str.strip() for text_col in text_cols]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # query that removes rows with null dt values\n",
    "    null_dt_filter = ' & '.join([f'({dte_col}.isnull() == False)' for dte_col in dte_cols])\n",
    "    \n",
    "    if flag_cols is None:\n",
    "        flag_cols = {}\n",
    "        \n",
    "    if dt_changes is None:\n",
    "        dt_changes = {}\n",
    "        \n",
    "    if text_changes is None:\n",
    "        text_changes = {}\n",
    "\n",
    "    events_new = (\n",
    "        events\n",
    "   #     .query('(usi in @zedmed_usi) == False')\n",
    "        .query(null_dt_filter)\n",
    "        .assign(**dt_clean) #\n",
    "        .assign(**dt_changes)\n",
    "        .assign(**text_changes)\n",
    "        .assign(**flag_cols)\n",
    "        .assign(event_type=event_name)\n",
    "        .rename(columns=rename_cols)\n",
    "        .query(f'dte.isnull() == False')\n",
    "        .loc[:, select_cols]\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "    \n",
    "    return events_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7bdf769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_vaed(vaed_proc):\n",
    "    \"\"\"\n",
    "    Filter VAED procedures to only those that correspond to bariatric surgery\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    vaed_proc (pd.DataFrame): VAED procedures dataframe\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    vaed_proc_events (pd.DataFrame): only those VAED procedures that match the criteria\n",
    "    \"\"\"\n",
    "    vaed_proc_events = (\n",
    "        vaed_proc\n",
    "        .loc[vaed_proc.procedure_code.str.startswith('30511') | vaed_proc.procedure_code.str.startswith('30512'), :]\n",
    "        .query('usi != \"\"')\n",
    "        .loc[:, ['usi', 'effective_dte', 'procedure_code']]\n",
    "        .rename(columns={'effective_dte': 'dte', 'procedure_code': 'value'})\n",
    "        .assign(event_type='vaed_surgery')\n",
    "        .assign(bariatric_surgery_flag=True)\n",
    "    )\n",
    "    \n",
    "    return vaed_proc_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78eadb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index_case_label(df, \n",
    "                         patientid='usi', \n",
    "                         date='date', \n",
    "                         case='uwl_flag'):\n",
    "    \"\"\"\n",
    "    Add a new column for the index date for each of the patients.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    df (pd.DataFrame): the input dataframe\n",
    "    patientid (str): the column name of the patientid field\n",
    "    date (str): the column name of the date field\n",
    "    csae (str): the column name of the case field\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    df (pd.DataFrame): dataframe with the index date column added\n",
    "    \"\"\"\n",
    "    df = df.copy().assign(index_case=False)\n",
    "    df.loc[df.groupby(patientid)[case].idxmax().values, 'index_case'] = True\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908391af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tables(encounters, diagnoses, pathology, prescription, hwbmi):\n",
    "    \"\"\"\n",
    "    Transform each of the event types, introducing relevant flags and renaming\n",
    "    columns\n",
    "    \"\"\"\n",
    "    # transform each of the source data tables, including adding flags\n",
    "    encounters_new = transform_table_standard(encounters, \n",
    "                                              rename_cols_encounters, \n",
    "                                              select_cols_encounters, \n",
    "                                              flag_cols=flag_cols_encounters, \n",
    "                                              dte_cols=['visit_dte'], \n",
    "                                              main_date_col='visit_dte',\n",
    "                                              text_cols=['encounter_reason'], \n",
    "                                              event_name='encounter')\n",
    "    \n",
    "    diagnoses_new = transform_table_standard(diagnoses, \n",
    "                                             rename_cols_diagnoses, \n",
    "                                             select_cols_diagnoses, \n",
    "                                             flag_cols=flag_cols_diagnoses, \n",
    "                                             dte_cols=['diagnosis_dte'], \n",
    "                                             main_date_col='diagnosis_dte',\n",
    "                                             text_cols=['diagnosis_reason'], \n",
    "                                             event_name='diagnosis')\n",
    "    \n",
    "    # the basic cohort consisting of encounters and diagnoses\n",
    "    # with patients who have at least one weight_flag = True event\n",
    "    cohort = (\n",
    "        pd.concat([encounters_new, diagnoses_new])\n",
    "    )\n",
    "    \n",
    "    usi_weight = cohort.query('weight_flag == True').usi.unique()\n",
    "    \n",
    "    cohort_small = (\n",
    "        cohort\n",
    "        .query('usi in @usi_weight')\n",
    "        .drop_duplicates()\n",
    "        .reset_index()\n",
    "        .iloc[:, 1:]\n",
    "    )\n",
    "    \n",
    "    # get the patients from this cohort\n",
    "    usi_basic = cohort_small.usi.unique()\n",
    "    \n",
    "    pathology_new = transform_table_standard(pathology.query('usi in @usi_basic'), \n",
    "                                             rename_cols_pathology, \n",
    "                                             select_cols_pathology, \n",
    "                                             flag_cols=None, \n",
    "                                             dte_cols=['result_dte'], \n",
    "                                             main_date_col='result_dte',\n",
    "                                             text_cols=['result_name_standard'], \n",
    "                                             event_name='pathology')\n",
    "    \n",
    "    prescription_new = transform_table_standard(prescription.query('usi in @usi_basic'), \n",
    "                                                rename_cols_prescription, \n",
    "                                                select_cols_prescription, \n",
    "                                                flag_cols_prescription, \n",
    "                                                dte_cols_prescription, \n",
    "                                                main_date_col='firstprescrip_dte',\n",
    "                                                text_cols=text_cols_prescription, \n",
    "                                                event_name='prescription')\n",
    "    \n",
    "    hwbmi_new = transform_table_standard(hwbmi.query('usi in @usi_basic'),\n",
    "                                         rename_cols_observations, \n",
    "                                         select_cols_observations, \n",
    "                                         flag_cols=None,\n",
    "                                         dte_cols=['observation_dte'], \n",
    "                                         main_date_col='observation_dte',\n",
    "                                         text_cols=['observation_type'], \n",
    "                                         event_name='observation')\n",
    "    \n",
    "    return cohort_small, pathology_new, prescription_new, hwbmi_new\n",
    "\n",
    "\n",
    "def filter_vaed_data(cohort, vaed_proc, cancer):\n",
    "    \"\"\"\n",
    "    Given a cohort of patients, vaed procedures and cancer cases, \n",
    "    filter the vaed and cancer data to only those relevant to cohort\n",
    "    \"\"\"    \n",
    "    \n",
    "    uwl_usi = cohort.usi.unique()\n",
    "    \n",
    "    # filter to VAED events related to bariatric surgery\n",
    "    vaed_proc = (\n",
    "        vaed_proc\n",
    "        .loc[vaed_proc.procedure_code.str.startswith('30511') | vaed_proc.procedure_code.str.startswith('30512'), :]\n",
    "        .query('usi != \"\"')\n",
    "        .loc[:, ['usi', 'effective_dte', 'procedure_code']]\n",
    "        .rename(columns={'effective_dte': 'dte', 'procedure_code': 'value'})\n",
    "        .assign(event_type='vaed_surgery')\n",
    "        .assign(bariatric_surgery_flag=True)\n",
    "    )\n",
    "    \n",
    "    # find first instance of cancer for each usi\n",
    "    cancer_uwl_first = (\n",
    "        cancer\n",
    "        .assign(usi=cancer.usi.astype(str).str.rjust(10, '0'))\n",
    "        .rename(columns={'incidence_dte': 'dte', 'diagnosis_icd10am_3cde': 'value'})\n",
    "        .query('usi in @uwl_usi')\n",
    "        .assign(dte=lambda df_: pd.to_datetime(df_.dte, format='%d%b%Y'))\n",
    "        .assign(event_type='cancer_diagnosis')\n",
    "        .loc[:, ['usi', 'dte', 'value', 'event_type']]\n",
    "        .sort_values(by=['usi', 'dte'])\n",
    "    )\n",
    "    \n",
    "    return vaed_proc, cancer_uwl_first\n",
    "\n",
    "def filter_cohort(cohort):\n",
    "    \"\"\"\n",
    "    Filter the cohort to only those with likely uwl encounters\n",
    "    \n",
    "    \"\"\"\n",
    "    # filter to patients who have a uwl_flag == True\n",
    "    uwl_candidates = (\n",
    "        cohort\n",
    "        .assign(dte=pd.to_datetime(cohort.dte))\n",
    "        .assign(dte=lambda df_: df_.dte.dt.normalize())\n",
    "        .assign(value=cohort.value.astype(str))\n",
    "        .query('weightloss_flag == True')\n",
    "        .query('weightloss_med_flag == False')\n",
    "        .query('weightloss_inquiry_flag == False')\n",
    "        .usi\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    cohort = (\n",
    "        cohort\n",
    "        .query('usi in @uwl_candidates')\n",
    "        .assign(uwl_flag=False)\n",
    "        .assign(uwl_flag=lambda df_: df_.uwl_flag.where(((df_.weightloss_flag == True) & \n",
    "                                                        (df_.weightloss_med_flag == False) & \n",
    "                                                        (df_.weightloss_inquiry_flag == False)) == False, True)) \n",
    "        .assign(usi_linked=lambda df_: df_.usi.str.startswith('G') == False, # flag for whether patient can be linked\n",
    "                index_case=0)\n",
    "    )\n",
    "    \n",
    "    return cohort\n",
    "\n",
    "def add_cancer_dates(cohort):\n",
    "    \"\"\"\n",
    "    Add flags to cohort describing events that are cancer diagnoses within 6 months of index date\n",
    "    and whether patient is diagnosed with cancer before index date\n",
    "    \"\"\"\n",
    "    # first cancer diagnosis date for each patient\n",
    "    cancer_diagnosis_date = (\n",
    "        cohort\n",
    "        .query('event_type == \"cancer_diagnosis\"')\n",
    "        .sort_values(by=['usi', 'dte'])\n",
    "        .groupby('usi')\n",
    "        .dte\n",
    "        .first()\n",
    "    )\n",
    "\n",
    "    # index dates for each patient\n",
    "    index_date = (\n",
    "        cohort\n",
    "        .query('at_index_date == True')\n",
    "        .sort_values(by=['usi', 'dte'])\n",
    "        .groupby('usi')\n",
    "        .dte\n",
    "        .first()\n",
    "    )\n",
    "    \n",
    "    # those patients who have a cancer diagnosis before the index date\n",
    "    cancer_before_index = (cancer_diagnosis_date - index_date) < '0 days'\n",
    "    usi_cancer_before_index = cancer_before_index[cancer_before_index].index\n",
    "    \n",
    "    # those patients who have a cancer diagnosis within 6 months of index date\n",
    "    time_delay1 = (cancer_diagnosis_date - index_date) <= '183 days'\n",
    "    usi_cancer_within_6months = time_delay1[time_delay1].index\n",
    "\n",
    "    cohort = (\n",
    "        cohort\n",
    "        .assign(cancer_before_index_date=lambda df_: df_.usi.isin(usi_cancer_before_index),\n",
    "                cancer_within_6months_index_date=lambda df_: df_.usi.isin(usi_cancer_within_6months))\n",
    "    )\n",
    "    \n",
    "    return cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb27b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cohort_new(cohort):\n",
    "    \"\"\"\n",
    "    Filter the cohort to only those with likely uwl encounters\n",
    "    \n",
    "    \"\"\"\n",
    "    # filter to patients who have a uwl_flag == True\n",
    "    uwl_candidates = (\n",
    "        cohort\n",
    "        .query('weightloss_flag == True')\n",
    "        .query('weightloss_med_flag == False')\n",
    "        .query('weightloss_inquiry_flag == False')\n",
    "        .usi\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    cohort = (\n",
    "        cohort\n",
    "        .query('usi in @uwl_candidates')\n",
    "        .assign(uwl_flag=False)\n",
    "        .assign(uwl_flag=lambda df_: df_.uwl_flag.where(((df_.weightloss_flag == True) & \n",
    "                                                        (df_.weightloss_med_flag == False) & \n",
    "                                                        (df_.weightloss_inquiry_flag == False)) == False, True)) \n",
    "        .assign(usi_linked=lambda df_: df_.usi.str.startswith('G') == False, # flag for whether patient can be linked\n",
    "                index_case=0)\n",
    "    )\n",
    "    \n",
    "    return cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8a031",
   "metadata": {},
   "source": [
    "## 4. Tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b2e2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols_new = ['usi',\n",
    "                  'dte',\n",
    "                  'event_type',\n",
    "                  'event_subtype',\n",
    "                  'value',\n",
    "                  'value2',\n",
    "                  'value3', \n",
    "                  'weight_flag',\n",
    "                  'weightloss_flag',\n",
    "                  'weightloss_inquiry_flag',\n",
    "                  'weightloss_med_flag',\n",
    "                  'bariatric_surgery_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2139f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename_encounter, \n",
    "              filename_diagnosis, \n",
    "              filename_prescription, \n",
    "              filename_patient, \n",
    "              filename_hwbmi,\n",
    "              filename_pathology,\n",
    "              filename_vaed_proc,\n",
    "              filename_cancer, \n",
    "              source_folder1, \n",
    "              source_folder2, \n",
    "              source_folder3, \n",
    "              source_folder4,\n",
    "              remove_zedmed=False):\n",
    "    \n",
    "    encounters_a1 = pd.read_parquet(f'{source_folder1}/{filename_encounter}')\n",
    "    diagnoses_a1 = pd.read_parquet(f'{source_folder1}/{filename_diagnosis}')\n",
    "    prescription_a1 = pd.read_parquet(f'{source_folder1}/{filename_prescription}').rename(columns=standard_cols_prescription)\n",
    "    patient_a1 = pd.read_parquet(f'{source_folder1}/{filename_patient}')\n",
    "\n",
    "    hwbmi_a1 = pd.read_parquet(f'{source_folder2}/{filename_hwbmi}')\n",
    "    pathology_a1 = pd.read_parquet(f'{source_folder2}/{filename_pathology}')\n",
    "\n",
    "    vaed_proc_a1 = pd.read_parquet(f'{source_folder3}/{filename_vaed_proc}')\n",
    "\n",
    "    cancer_a1 = pd.read_csv(f'{source_folder4}/{filename_cancer}')\n",
    "\n",
    "    # remove ZedMed patients from Patron\n",
    "    zedmed_usi = pd.read_csv('M:/Working/DataAnalysis/CleanAndStructure/PAT012_ZM_USI.csv').Patient_USI.values\n",
    "\n",
    "    # patientid to usi\n",
    "    patientid_to_usi = dict(patient_a1[['patientid', 'usi']].values)\n",
    "\n",
    "    # usi to patientid\n",
    "    usi_to_patientid = dict(patient_a1[['usi', 'patientid']].values)\n",
    "\n",
    "    pathology_a1.result_dte = pd.to_datetime(pathology_a1.result_dte, format='%d%b%Y', errors='coerce')\n",
    "\n",
    "    # convert usi \n",
    "    patient_a1.usi = patient_a1.usi.astype(str)\n",
    "    cancer_a1.usi = cancer_a1.usi.astype(str).str.rjust(10, '0')\n",
    "\n",
    "    # include usi in all the events tables\n",
    "    encounters_a1 = (\n",
    "        encounters_a1\n",
    "        .assign(usi=lambda df_: df_.patientid.map(patientid_to_usi))\n",
    "    )\n",
    "\n",
    "    diagnoses_a1 = (\n",
    "        diagnoses_a1\n",
    "        .assign(usi=lambda df_: df_.patientid.map(patientid_to_usi))\n",
    "    )\n",
    "\n",
    "    prescription_a1 = (\n",
    "        prescription_a1\n",
    "        .assign(usi=lambda df_: df_.patientid.map(patientid_to_usi))\n",
    "    )\n",
    "\n",
    "    hwbmi_a1 = (\n",
    "        hwbmi_a1\n",
    "        .assign(usi=lambda df_: df_.patientid.map(patientid_to_usi))\n",
    "    )\n",
    "\n",
    "    pathology_a1 = (\n",
    "        pathology_a1\n",
    "        .assign(usi=lambda df_: df_.patientid.map(patientid_to_usi))\n",
    "    )\n",
    "\n",
    "    vaed_proc_a1 = (\n",
    "        vaed_proc_a1\n",
    "    #    .assign(usi=lambda df_: df_.patientid.map(patientid_to_usi))\n",
    "    )\n",
    "\n",
    "    cancer_a1 = (\n",
    "        cancer_a1\n",
    "    #    .assign(usi=lambda df_: df_.patientid.map(patientid_to_usi))\n",
    "    )\n",
    "    \n",
    "    # if we want to remove the zedmed usi\n",
    "    if remove_zedmed:\n",
    "        encounters_a1 = encounters_a1.query('(usi in @zedmed_usi) == False')\n",
    "        diagnoses_a1 = diagnoses_a1.query('(usi in @zedmed_usi) == False')\n",
    "        prescription_a1 = prescription_a1.query('(usi in @zedmed_usi) == False')\n",
    "        hwbmi_a1 = hwbmi_a1.query('(usi in @zedmed_usi) == False')\n",
    "        pathology_a1 = pathology_a1.query('(usi in @zedmed_usi) == False')\n",
    "        vaed_proc_a1 = vaed_proc_a1.query('(usi in @zedmed_usi) == False')\n",
    "        cancer_a1 = cancer_a1.query('(usi in @zedmed_usi) == False')\n",
    "    \n",
    "    return encounters_a1, diagnoses_a1, prescription_a1, patient_a1, hwbmi_a1, pathology_a1, vaed_proc_a1, cancer_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a5d658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_log(cohort_small, prescription, hwbmi, pathology, vaed, cancer):\n",
    "    \n",
    "    cohort_small_new = pd.concat([cohort_small, \n",
    "                                  prescription, \n",
    "                                  hwbmi, \n",
    "                                  pathology])\n",
    "\n",
    "    # filter vaed data to potential uwl patients\n",
    "    vaed_new, cancer_uwl = filter_vaed_data(cohort_small_new, vaed, cancer)\n",
    "\n",
    "    # the event log\n",
    "    cohort_new = pd.concat([cohort_small_new, \n",
    "                           prescription,\n",
    "                           hwbmi, \n",
    "                           pathology,\n",
    "                           cancer_uwl, \n",
    "                           vaed_new])[final_cols_new].drop_duplicates()\n",
    "\n",
    "    # fill in missing flag values with False\n",
    "    cohort_new = (\n",
    "        cohort_new\n",
    "        .assign(weight_flag=lambda df_: df_.weight_flag.fillna(False),\n",
    "                weightloss_flag=lambda df_: df_.weightloss_flag.fillna(False),\n",
    "                weightloss_inquiry_flag=lambda df_: df_.weightloss_inquiry_flag.fillna(False),\n",
    "                weightloss_med_flag=lambda df_: df_.weightloss_med_flag.fillna(False), \n",
    "                bariatric_surgery_flag=lambda df_: df_.bariatric_surgery_flag.fillna(False))\n",
    "    )    \n",
    "\n",
    "    # convert values to strings and tidy\n",
    "    cohort_new = (\n",
    "        cohort_new\n",
    "        .assign(value=lambda df_: df_.value.str.upper().str.strip())\n",
    "        .assign(value2=lambda df_: df_.value2.str.upper().str.strip())\n",
    "        .assign(value3=lambda df_: df_.value3.str.upper().str.strip())\n",
    "    )\n",
    "    \n",
    "    return cohort_new\n",
    "\n",
    "def tidy_event_log(events):\n",
    "    cols = ['usi', 'dte', 'value', 'value2', 'value3', 'event_type', 'weight_flag', 'weightloss_flag',\n",
    "           'weightloss_inquiry_flag', 'bariatric_surgery_flag', \n",
    "           'weightloss_med_flag', 'event_subtype']\n",
    "\n",
    "    # the event log\n",
    "    events_new = (\n",
    "        events\n",
    "        .loc[:, cols]\n",
    "        .assign(weight_flag=lambda df_: df_.weight_flag.fillna(False),\n",
    "                weightloss_flag=lambda df_: df_.weightloss_flag.fillna(False),\n",
    "                weightloss_inquiry_flag=lambda df_: df_.weightloss_inquiry_flag.fillna(False), \n",
    "                weightloss_med_flag=lambda df_: df_.weightloss_med_flag.fillna(False), \n",
    "                bariatric_surgery_flag=lambda df_: df_.bariatric_surgery_flag.fillna(False))\n",
    "        .query('usi != \"\"')\n",
    "        .sort_values(by=['usi', 'dte'])\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "\n",
    "    # consider only those usi values that have at least one weightloss_flag == True \n",
    "    usi_wl_a2 = (\n",
    "        events_new\n",
    "        .query('weightloss_flag == True')\n",
    "        .usi\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    events_final = (\n",
    "        events_new\n",
    "        .query('usi in @usi_wl_a2')\n",
    "    )\n",
    "\n",
    "    events_final = (\n",
    "        events_final\n",
    "        .assign(dte=lambda df_: pd.to_datetime(df_.dte, format='%Y-%m-%d'))\n",
    "        .assign(dte=lambda df_: df_.dte.dt.normalize())\n",
    "        .assign(value=lambda df_: df_.value.astype(str))\n",
    "        .reset_index()\n",
    "        .iloc[:, 1:]\n",
    "    )\n",
    "    \n",
    "    return events_final\n",
    "\n",
    "def create_final_cohort(cohort):\n",
    "    uwl_candidates = (\n",
    "        cohort\n",
    "        .query('weightloss_flag == True')\n",
    "        .query('weightloss_med_flag == False')\n",
    "        .query('weightloss_inquiry_flag == False')\n",
    "        .query('weight_increase == False')\n",
    "        .query('bariatric_surgery_flag == False')\n",
    "        .query('cancer_before_index_date == False')\n",
    "        .loc[:, 'usi']\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    cohort_uwl = (\n",
    "        cohort\n",
    "        .query('usi in @uwl_candidates')\n",
    "    )\n",
    "\n",
    "    usi_previous_med = (\n",
    "        cohort_uwl.query('weightloss_med_flag == True')\n",
    "        .query('two_years_before == True')[['usi', 'usi_linked']]\n",
    "        .drop_duplicates()\n",
    "     #   .query('usi_linked == True')\n",
    "    ).usi.values\n",
    "\n",
    "    usi_previous_bariatric = (\n",
    "        cohort_uwl.query('bariatric_surgery_flag == True')\n",
    "        .query('six_months_before == True')[['usi', 'usi_linked']]\n",
    "        .drop_duplicates()\n",
    "      #  .query('usi_linked == True')\n",
    "    ).usi.values\n",
    "\n",
    "    cohort_uwl = (\n",
    "        cohort_uwl\n",
    "        .query('usi not in @usi_previous_bariatric')\n",
    "        .query('usi not in @usi_previous_med')\n",
    "    )\n",
    "    \n",
    "    return cohort_uwl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f95198",
   "metadata": {},
   "source": [
    "## 5. Create the cohort\n",
    "\n",
    "### Load and transform data to create event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c27f7a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for patron\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data for patron\")\n",
    "encounters_patron, diagnoses_patron, prescription_patron, patient_patron, hwbmi_patron, pathology_patron, vaed_proc_a1, cancer_a1 = load_data(filename_encounter_patron, \n",
    "                                                                                                                      filename_diagnosis_patron,\n",
    "                                                                                                                      filename_prescription_patron,\n",
    "                                                                                                                      filename_patient_patron,\n",
    "                                                                                                                      filename_hwbmi_patron,\n",
    "                                                                                                                      filename_pathology_patron,\n",
    "                                                                                                                      filename_vaed_proc,\n",
    "                                                                                                                      filename_cancer,\n",
    "                                                                                                                      source_folder1_patron,\n",
    "                                                                                                                      source_folder2_patron,\n",
    "                                                                                                                      source_folder3_patron,\n",
    "                                                                                                                      source_folder4_patron,\n",
    "                                                                                                                      remove_zedmed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "14073a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_all = (\n",
    "    encounters_patron\n",
    "    .assign(dte=lambda df_: format_dates(df_.visit_dte, date_formats=['%Y-%m-%d']))\n",
    "#    .query('dte.dt.year >= 2020')\n",
    " #   .query('dte.dt.year <= 2020')\n",
    "    .reset_index()\n",
    " #   .loc[:, ['patientid', 'usi', 'visit_dte', 'encounter_reason']]\n",
    ")\n",
    "\n",
    "diagnoses_all = (\n",
    "    diagnoses_patron\n",
    "    .assign(dte=lambda df_: format_dates(df_.diagnosis_dte))\n",
    "   # .query('dte.dt.year >= 2020')\n",
    "   # .query('dte.dt.year <= 2020')\n",
    "    .reset_index()\n",
    " #   .loc[:, ['patientid', 'usi', 'diagnosis_reason', 'diagnosis_dte', 'diagnosis_status_active_flg']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "21e02571",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_diag = pd.concat([encounters_all, diagnoses_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9f36e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prescriptions\n",
    "prescription_all = prescription_patron\n",
    "\n",
    "# prescriptions\n",
    "patient_all = patient_patron\n",
    "\n",
    "# prescriptions\n",
    "hwbmi_all = hwbmi_patron\n",
    "\n",
    "# prescriptions\n",
    "pathology_all = pathology_patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299bd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many patients to start with?\n",
    "num_patients_step1 = patient_all.usi.unique().shape[0]\n",
    "num_patients_step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f3be3d5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming tables\n",
      "Creating event log\n",
      "Tidying event log\n"
     ]
    }
   ],
   "source": [
    "print(\"Transforming tables\")\n",
    "# creates the flags for weight loss, weight loss inquiry, weight, and bariatric surgery.\n",
    "cohort_small_a2, pathology_new_a2, prescription_new_a2, hwbmi_new_a2 = transform_tables(encounters_all, \n",
    "                                                                                        diagnoses_all, \n",
    "                                                                                        pathology_all, \n",
    "                                                                                        prescription_all,\n",
    "                                                                                        hwbmi_all)\n",
    "\n",
    "print(\"Creating event log\")\n",
    "# creates an event log with all the event types along with a flag for weight loss prescription\n",
    "cohort_small_new_a2 = create_event_log(cohort_small_a2, \n",
    "                                       prescription_new_a2, \n",
    "                                       hwbmi_new_a2, \n",
    "                                       pathology_new_a2, \n",
    "                                       vaed_proc_a1, \n",
    "                                       cancer_a1)\n",
    "\n",
    "print(\"Tidying event log\")\n",
    "# cleans datetimes, removes empty usi values and filters to usi values that have weightloss_flag == True\n",
    "cohort_small_new_a2 = tidy_event_log(cohort_small_new_a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_small_a2.usi.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many patients have a weight_flag == True event?, how many encounters correspond to these?\n",
    "cohort_small_a2.query('weight_flag == True').usi.unique().shape[0], cohort_small_a2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many have weightloss_flag == True event, i.e., have a weight regex and a loss regex?\n",
    "usi_weightloss = cohort_small_a2.query('weightloss_flag == True').usi.unique()\n",
    "usi_weightloss.shape[0], cohort_small_a2.query('usi in @usi_weightloss').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many have weightloss_inquiry_flag == True, i.e., have weightloss_flag == True and an inquiry regex?\n",
    "usi_weightloss_inquiry = cohort_small_a2.query('weightloss_inquiry_flag == True').usi.unique()\n",
    "usi_weightloss_inquiry.shape[0], cohort_small_a2.query('usi in @usi_weightloss_inquiry').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf28a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many have weightloss_flag == True and weightloss_inquiry_flag == False\n",
    "usi_weightloss_no_inquiry = cohort_small_a2.query('weightloss_flag == True').query('weightloss_inquiry_flag == False').usi.unique()\n",
    "usi_weightloss_no_inquiry.shape[0], cohort_small_a2.query('usi in @usi_weightloss_no_inquiry').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many have bariatric_surgery == True\n",
    "usi_bariatric = cohort_small_a2.query('bariatric_surgery_flag == True').usi.unique()\n",
    "usi_bariatric.shape[0], cohort_small_a2.query('usi in @usi_bariatric').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3de561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many are candidates at this stage? e.g., (weightloss_flag == True) & (weightloss_inquiry_flag == True) & (bariatric_surgery_flag == False)\n",
    "usi_candidates_step2 = cohort_small_a2.query('weightloss_flag == True').query('weightloss_inquiry_flag == False').query('bariatric_surgery_flag == False').usi.unique()\n",
    "usi_candidates_step2.shape[0], cohort_small_a2.query('usi in @usi_candidates_step2').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_small_new_a2.query('weightloss_flag == True').usi.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c75b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of patients with weightloss_flag == True\n",
    "cohort_small_new_a2.usi.unique().shape[0], cohort_small_new_a2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7397ef9",
   "metadata": {},
   "source": [
    "### Make predictions of UWL / not UWL based on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3aaf8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text processing\n",
    "weight_measurement_pattern2 = r'([0-9]+\\s{0,1}kg)'\n",
    "weight_measurement_pattern1 = r'([0-9]+\\.[0-9]+\\s{0,1}kg)'\n",
    "weight_measurement_pattern = r'|'.join([weight_measurement_pattern1, weight_measurement_pattern2])\n",
    "\n",
    "number_pattern = r'([0-9]+)'\n",
    "months_pattern = r'([0-9]+)\\s{0,1}\\/\\s{0,1}12'\n",
    "weeks_pattern = r'([0-9]+)\\s{0,1}\\/\\s{0,1}52'\n",
    "days_pattern = r'([0-9]+)\\s{0,1}\\/\\s{0,1}7'\n",
    "\n",
    "token_pattern = r'([\\!\\/\\?\\+\\<\\>])'\n",
    "remove_pattern = r'[\\.\\,\\;\\:\\-\\(\\)]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0ad41b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(texts):\n",
    "    \"\"\"\n",
    "    Preprocessing of strings from encounter reasons to ensure\n",
    "    relevant non-alphanumeric characters are treated as tokens\n",
    "    and others are removed.\n",
    "    \n",
    "    Args\n",
    "    texts (pd.Series): input reasons for encounter texts \n",
    "    \n",
    "    Return\n",
    "    texts (pd.Series): the processed text after applying transformations\n",
    "    \"\"\"\n",
    "    texts = (texts\n",
    "             .str.lower()\n",
    "             .str.replace(weeks_pattern, '\\g<1> weeks', regex=True)\n",
    "             .str.replace(days_pattern, '\\g<1> days', regex=True)\n",
    "             .str.replace(months_pattern, '\\g<1> months', regex=True)\n",
    "             .str.replace(weight_measurement_pattern, '[weight_measurement]', regex=True)\n",
    "             .str.replace(number_pattern, '[number_value]', regex=True)\n",
    "             .str.replace(token_pattern, ' \\g<1> ', regex=True)\n",
    "             .str.replace(remove_pattern, ' ', regex=True)\n",
    "             .str.replace('[ ]+', ' ', regex=True)\n",
    "             .str.strip()\n",
    "            )\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ca586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens that relate to positive sentiment (label 3)\n",
    "features_group1 = ['excellent', 'great', 'good', 'vg', '!', 'success', \n",
    "                   'spectacular', 'well', 'improved', 'very']\n",
    "\n",
    "# tokens that indicate actions to lose weight (label 3)\n",
    "features_group2 = ['exercise', 'diet', 'start', 'restart', 'aim', 'target', \n",
    "                   'struggle', 'difficult', 'trouble']\n",
    "\n",
    "# tokens that indicate some sort of weight loss treatment (label 3)\n",
    "features_group3 = ['request', 'therapy', 'drug', 'treament', 'medication', 'med', 'tab']\n",
    "\n",
    "# tokens that indicate mood disorder (label 2)\n",
    "features_group4 = ['depression', 'anxiety', 'anxious', 'depressed', 'mood']\n",
    "\n",
    "# tokens that indicate patient seeking advice on how to lose weight (label 3)\n",
    "features_group5 = ['talk', 'advise', 'advice', 'discuss', 'consider', 'strategy', \n",
    "                   'education', 'counsel', 'program', 'mx']\n",
    "\n",
    "# tokens that also relate to weight loss being intentional or trying to lose weighyt (label 3)\n",
    "features_group6 = ['holiday', 'surgery', 'overweight', 'gain']\n",
    "\n",
    "# intention (label 1)\n",
    "features_group7 = ['unintentional', 'unexplained', 'unintended', 'no cause']\n",
    "\n",
    "# investigations (label 1)\n",
    "features_group8 = ['fi', 'f.i.', 'f.i', 'f/i', 'ix', 'investigation']\n",
    "\n",
    "# weight loss symptom (label 1)\n",
    "features_group9 = ['cachexic', 'cachexia', 'anorexia']\n",
    "\n",
    "# cancer symptom (label 1)\n",
    "features_group10 = ['nausea', 'tiredness', 'cough', 'sweats', 'splenomegaly', \n",
    "                    'abdo', 'diarrhoea', 'appetite', 'lethargy', 'tired', 'anaemia', 'anemia']\n",
    "\n",
    "# combine the tokens into negative (unlikely due to UWL) and positive (may be due to UWL)\n",
    "features_negative = features_group1 + features_group2 + features_group3 + features_group5 + features_group6\n",
    "features_positive = features_group4 + features_group7 + features_group8 + features_group9 + features_group10\n",
    "\n",
    "len(set(features_negative)), len(set(features_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "42ec1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplest classifier: check if there are positive or negative features and classify accordingly\n",
    "regex_neg = r'|'.join(features_negative)\n",
    "regex_pos = r'|'.join(features_positive)\n",
    "\n",
    "def uwl_classifier(text, uwl_terms, nonuwl_terms):\n",
    "    num_uwl_terms = sum([term in text for term in uwl_terms])\n",
    "    num_nonuwl_terms = sum([term in text for term in nonuwl_terms])\n",
    "    \n",
    "    if num_nonuwl_terms > num_uwl_terms:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e881fe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create cohort of UWL candidate patients\n"
     ]
    }
   ],
   "source": [
    "print(\"Create cohort of UWL candidate patients\")\n",
    "cohort_final_new_a2 = (\n",
    "    filter_cohort_new(cohort_small_new_a2)\n",
    "    .assign(dte=lambda df_: pd.to_datetime(df_.dte))\n",
    "    .query('dte.isnull() == False')\n",
    "   # .pipe(add_index_case_label, patientid='usi')\n",
    "    .reset_index()\n",
    "    .iloc[:, 1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1fb0de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_final_new_a2.usi.unique().shape, cohort_final_new_a2.query('uwl_flag == True').query('usi_linked == True').usi.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c2830e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification algorithm on candidate texts\n",
    "cohort_final_new_a2 = (\n",
    "    cohort_final_new_a2\n",
    "    .assign(text_processed=lambda df_: text_processing(df_.value))\n",
    ")\n",
    "\n",
    "uwl_candidate_texts = cohort_final_new_a2.text_processed.values\n",
    "uwl_candidate_preds = np.array([uwl_classifier(text, features_positive, features_negative) for text in uwl_candidate_texts])\n",
    "\n",
    "cohort_final_new_a2 = (\n",
    "    cohort_final_new_a2\n",
    "    .assign(uwl_prediction=uwl_candidate_preds)\n",
    ")\n",
    "\n",
    "# set those that have a prediction of 0 based on the classifier to have uwl_flag == False\n",
    "cohort_final_new_a2.loc[cohort_final_new_a2.query('uwl_flag == True').query('uwl_prediction == 0').index, 'uwl_flag'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many candidates are there are this stage?\n",
    "usi_candidates_final_stage = cohort_final_new_a2.usi.unique()\n",
    "usi_candidates_final_stage.shape[0], cohort_final_new_a2.query('usi in @usi_candidates_final_stage').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe453e2",
   "metadata": {},
   "source": [
    "### Create index date and time period flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d68ce891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create cohort of UWL candidate patients\n",
      "Adding time period flags\n",
      "Add dates of cancer diagnoses\n",
      "Remove patients with a weight increase\n",
      "Final cohort\n"
     ]
    }
   ],
   "source": [
    "print(\"Create cohort of UWL candidate patients\")\n",
    "cohort_final_new_a2 = (\n",
    "    cohort_final_new_a2\n",
    " #   filter_cohort_new(cohort_small_new_a2)\n",
    "  #  .assign(dte=lambda df_: pd.to_datetime(df_.dte))\n",
    "  #  .query('dte.isnull() == False')\n",
    "    .pipe(add_index_case_label, patientid='usi')\n",
    "    .reset_index()\n",
    "    .iloc[:, 1:]\n",
    ")\n",
    "\n",
    "print(\"Adding time period flags\")\n",
    "cohort_final_new_a2 = (\n",
    "    cohort_final_new_a2\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(0, 31), time_period_label='one_month_after')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(0, 92), time_period_label='three_months_after')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(0, 183), time_period_label='six_months_after')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(0, 366), time_period_label='one_year_after')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(0, 731), time_period_label='two_years_after')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(0, 1828), time_period_label='five_years_after')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(-31, 0), time_period_label='one_month_before')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(-92, 0), time_period_label='three_months_before')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(-183, 0), time_period_label='six_months_before')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(-366, 0), time_period_label='one_year_before')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(-731, 0), time_period_label='two_years_before')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(-1828, 0), time_period_label='five_years_before')\n",
    "    .pipe(events_within_time_period, date='dte', time_period=(0, 0), time_period_label='at_index_date')\n",
    ")\n",
    "\n",
    "print(\"Add dates of cancer diagnoses\")\n",
    "cohort_final_new_a2 = add_cancer_dates(cohort_final_new_a2)\n",
    "\n",
    "print(\"Remove patients with a weight increase\")\n",
    "# patients who have an observed weight increase\n",
    "cohort_final_new_a2 = (\n",
    "    cohort_final_new_a2\n",
    "    .query('dte.isnull() == False')\n",
    "    .groupby('usi')\n",
    "    .apply(lambda df_: weight_increase(df_))\n",
    ")\n",
    "\n",
    "print(\"Final cohort\") # remove patients who have had previous bariatric surgery and on weight loss medication\n",
    "cohort_uwl = create_final_cohort(cohort_final_new_a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09550663",
   "metadata": {},
   "outputs": [],
   "source": [
    "usi_uwl_final = cohort_uwl.query('uwl_flag == True').usi.unique()\n",
    "usi_uwl_final.shape[0], cohort_uwl.query('usi in @usi_uwl_final').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617aa2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_uwl.usi.unique().shape[0], cohort_uwl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9311c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data\n",
    "cohort_uwl.to_parquet(\"M:/Working/AL/projects/weight_loss/outputs/uwl_cohort_patron_010823.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
