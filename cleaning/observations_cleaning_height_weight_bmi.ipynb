{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cecc5d5",
   "metadata": {},
   "source": [
    "# Data cleaning of height, weight, BMI\n",
    "\n",
    "1 March 2023\n",
    "\n",
    "---\n",
    "\n",
    "## Description\n",
    "\n",
    "Notebook that carries out the cleaning steps for the height, weight and BMI observations in the NPS data.\n",
    "\n",
    "## Steps\n",
    "\n",
    "### 1. Initial cleaning of weights\n",
    "\n",
    "- Removing non-numeric characters\n",
    "- Corrections based on units\n",
    "\n",
    "### 2. Initial cleaning of heights\n",
    "\n",
    "- Removing non-numeric characters\n",
    "- Corrections based on units\n",
    "\n",
    "### 3. Initial cleaning of BMI\n",
    "\n",
    "- Removing non-numeric characters\n",
    "\n",
    "### 4. Extreme weights\n",
    "\n",
    "- All those that are > 400\n",
    "\n",
    "### 5. Extreme heights\n",
    "\n",
    "- All those that are > 300 or < 140\n",
    "\n",
    "### 6. Extreme BMI\n",
    "\n",
    "- This is incomplete as it is not yet neccessary\n",
    "\n",
    "### 7. Combined height, weight, BMI cleaning\n",
    "\n",
    "- Correct for errors where the GP has interchanged weight and height values, resulting in inconsistent BMI values.\n",
    "\n",
    "### 8. Any final cleaning\n",
    "\n",
    "- Scale weights < 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5617e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c14dda",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da06585",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cff3ec",
   "metadata": {},
   "source": [
    "## Load up raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4dc953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder2 = \"M:/Working/AL/projects/weight_loss/outputs\"\n",
    "source_folder = 'M:/Working/DataAnalysis/CleanAndStructure/DataFiles'\n",
    "\n",
    "filename_observation = \"NPS_Observation_202005.parquet\"\n",
    "filename_patient = \"NPS_Patient_202107.parquet\"\n",
    "filename_uwl_cohort = \"uwl_cohort_020322.parquet\"\n",
    "\n",
    "filename_observation = \"NPS_Observation_202005.csv\"\n",
    "filename_patient = \"NPS_Patient_202107.csv\"\n",
    "filename_uwl_cohort = \"uwl_cohort_020322.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ff0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observation = pd.read_parquet(f'{source_folder}/{filename_observation}')\n",
    "observation = pd.read_csv(f'{source_folder}/{filename_observation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e09c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient = pd.read_parquet(f'{source_folder}/{filename_patient}')\n",
    "patient = pd.read_csv(f'{source_folder}/{filename_patient}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "301a6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohort = pd.read_parquet(f'{source_folder2}/{filename_uwl_cohort}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be8fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the usi in the observations\n",
    "patientid_to_usi = dict(patient[['patientid', 'usi']].values)\n",
    "observation['usi'] = observation['patientid'].apply(lambda p: patientid_to_usi[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98051fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict the observations to the UWL cohort for now\n",
    "#usi_uwl = cohort['usi'].unique()\n",
    "#observation = observation[observation['usi'].isin(usi_uwl)].reset_index().iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a02bd",
   "metadata": {},
   "source": [
    "## Filter to weight, height and BMI observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ab1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = observation[observation['observation_type'] == 'WEIGHT']\n",
    "heights = observation[observation['observation_type'] == 'HEIGHT']\n",
    "bmis = observation[observation['observation_type'] == 'BMI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1274d1",
   "metadata": {},
   "source": [
    "## 1. Cleaning weights\n",
    "\n",
    "Remove unnecessary characters to get numeric values. Use the regular expressions defined below in  ```patterns_weight```. The types of corrections that these make are described on the confluence documentation, but overall are to remove unncessary characters, correct unusual decimal points and return only numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9627bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_weight = {r'(.)[^0-9\\.]+$': '\\g<1>',\n",
    "                   r\"^([0-9]+)\\s?[\\,\\:\\;\\'\\`]\\s?([0-9]+)$\": '\\g<1>.\\g<2>',\n",
    "                   r'^([0-9]+)\\-{1,2}([0-9]+)$': '\\g<1>', \n",
    "                   r'^([0-9]+)[\\.\\,\\s/\\(\\)]+([0-9]+)$': '\\g<1>.\\g<2>', \n",
    "                   r'^([0-9]+)[\\.\\,\\s/]+$': '\\g<1>', \n",
    "                   r'^[^0-9]+([0-9]+)$': '\\g<1>',\n",
    "                   r'^[^0-9]+$': '0', \n",
    "                   r\"^([0-9]+)[\\.\\,\\;\\:\\/=abc\\-\\'\\`]+([0-9]+)\": '\\g<1>.\\g<2>', \n",
    "                   r'^[^0-9]+([0-9]+)\\.([0-9]+)[^0-9]+$': '\\g<1>.\\g<2>',\n",
    "                   r'^[^0-9]+([0-9]+)\\.([0-9]+)$': '\\g<1>.\\g<2>', \n",
    "                   r'^([0-9]+)\\.([0-9]+)[^0-9]+$': '\\g<1>.\\g<2>', \n",
    "                   r'^([0-9]+)[^0-9]+$': '\\g<1>', \n",
    "                   r'^([0-9]+)\\s?kg.': '\\g<1>', \n",
    "                   r'^([0-9])\\.([0-9])\\.([0-9])$': '\\g<1>0\\g<2>.\\g<3>',\n",
    "                   r'^([0-9])\\s([0-9])(.)': '\\g<1>\\g<2>\\g<3>',\n",
    "                   r'^([0-9])\\+([0-9])$': '\\g<1>\\g<2>',\n",
    "                   r'^8st10$': '51',\n",
    "                   r'^([0-9])t([0-9])$': '\\g<1>\\g<2>',\n",
    "                   r'^([0-9]+)\\.l([0-9]+)$': '\\g<1>.\\g<2>',\n",
    "                   r'6y2': '0',\n",
    "                   r'\\+n\\s[0-9]': '0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "11845bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for cleaned data\n",
    "weights.loc[:, 'observation_value_cleaned'] = weights.loc[:, 'observation_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0410994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry out replacements based on regexes\n",
    "for key, value in patterns_weight.items():\n",
    "    weights.loc[:, 'observation_value_cleaned'] = weights.loc[:, 'observation_value_cleaned'].str.replace(key, value, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "deb48735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty values with 0 so these can be converted to floats\n",
    "weights.loc[:, 'observation_value_cleaned'] = weights['observation_value_cleaned'].str.replace(r'^$', '0', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e024b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float\n",
    "weights.loc[:, 'observation_value_cleaned'] = weights.loc[:, 'observation_value_cleaned'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6299b40f",
   "metadata": {},
   "source": [
    "## 2. Cleaning heights\n",
    "\n",
    "- Remove unncessary characters\n",
    "- Convert units where neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a55eed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    \"\"\"\n",
    "    Check to see if value can be converted to float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        a = float(value)\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "def convert_imperial(value, imperial_patterns):\n",
    "    \"\"\"\n",
    "    Convert a value in imperial units to metric\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    value (str): string representing imperial value (in feet)\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    value_tidy (str): string representing metric value (in cm)\n",
    "    \"\"\"\n",
    "    value_tidy = value\n",
    "    \n",
    "    for pattern, replacement in imperial_patterns.items():\n",
    "        value_tidy = re.sub(pattern, replacement, value_tidy)\n",
    "        \n",
    "    feet, inches = value_tidy.split('.')\n",
    "    value_tidy = float(feet)*30.48 + float(inches)*2.5\n",
    "    return value_tidy\n",
    "\n",
    "\n",
    "# patterns to tidy up data that is metric but has characters\n",
    "patterns_height_metric = {r'^([0-9]{3})\\s{0,1}c{0,1}m{0,1}s{0,1}': '\\g<1>', \n",
    "                          r'^([0-9]{3}\\.[0-9])\\s{0,1}cm{0,1}s{0,1}': '\\g<1>',\n",
    "                          r'^[^0-9]+$': '0', \n",
    "                          r'^([0-9]{3})\\,([0-9])$': '\\g<1>.\\g<2>', \n",
    "                          r'^([0-9]{3}).+': '\\g<1>', \n",
    "                          r'^\\@\\s{0,1}([0-9]{3})$': '\\g<1>', \n",
    "                          r'^\\`([0-9]{3})$': '\\g<1>',\n",
    "                          r'^(1)\\.([0-9]{1,2,3})\\s{0,1}m{0,1}$': '\\g<1>\\g<2>', \n",
    "                          r'1\\`([0-9]{2})[^0-9]*': '1\\g<1>', \n",
    "                          r'^1\\s{0,1}m([0-9]{2})\\s{0,1}c{0,1}m{0,1}$': '1\\g<1>', \n",
    "                          r'^([0-9]{2})\\s{0,1}cm{0,1}s{0,1}$': '1\\g<1>', \n",
    "                          r'^([0-9])\\.([0-9]{1})\\s{0,1}m$': '\\g<1>\\g<2>0', \n",
    "                          r'^([0-9])\\.([0-9]{2})\\s{0,1}m$': '\\g<1>\\g<2>'} \n",
    "\n",
    "\n",
    "# tidy up data in imperial units that has characters\n",
    "patterns_height_imperial = {r'^([0-9])\\'\\s{0,1}([0-9]{1,2})\\s{0,1}\\'{0,1}$': '\\g<1>.\\g<2>',\n",
    "                            r'^([0-9])\\`([0-9]{1,2})\\`{0,1}$': '\\g<1>.\\g<2>',\n",
    "                            r'^([0-9])\\s{0,1}ft\\s{0,1}[^0-9]+$': '\\g<1>.0',\n",
    "                            r'^([0-9])\\s{0,1}ft\\s{0,1}([0-9]).*$': '\\g<1>.\\g<2>',\n",
    "                            r'^([0-9])\\s{0,1}/([0-9]).*$': '\\g<1>.\\g<2>', \n",
    "                            r'^([0-9])\\s([0-9]{1,2})$': '\\g<1>.\\g<2>', \n",
    "                            r'^([0-9])\\s{0,1}-\\s{0,1}([0-9]{1,2})$': '\\g<1>.\\g<2>', \n",
    "                            r'^([0-9])\\s{0,1}\\.\\s{0,1}([0-9]{1,2})\\\"$': '\\g<1>.\\g<2>', \n",
    "                            r'^([0-9])\\s{0,1}(\\-|\\.|\\,|\\')\\s{0,1}([0-9]{1,2})(\\\"{0,1}|\\'\\')$': '\\g<1>.\\g<3>', \n",
    "                            r'^([0-9])\\s{0,1}ft$': '\\g<1>.0', \n",
    "                            r'^([0-9])\\s{0,1}(ft|f)\\s{0,1}([0-9]{1,2})$': '\\g<1>.\\g<3>', \n",
    "                            r'^([0-9])\\s{0,1}\\.\\s{0,1}([0-9]{1,2})(ft|\\'|\\\"|\\`|in)$': '\\g<1>.\\g<2>',  \n",
    "                            r'^([0-9])\\'$': '\\g<1>.0', \n",
    "                            r'^([0-9]{2})\\s{0,1}inches$': '0.\\g<1>', \n",
    "                            r'^([456])\\'([0-9])\\.5$': '\\g<1>.\\g<2>' \n",
    "                           }\n",
    "\n",
    "\n",
    "# additional transformations for cleaning\n",
    "patterns_height = {r'([0-9]+)[^0-9\\.]+$': '\\g<1>', # number followed by non-numbers\n",
    "            r'^([0-9]+)\\s?[\\,\\:\\;\\'\\`]\\s?([0-9]+)$': '\\g<1>.\\g<2>', # decimals with another character rather than decimal\n",
    "            r'^([0-9]+)\\-{1,2}([0-9]+)$': '\\g<1>', # integers followed by trailing - characters then number\n",
    "            r'^([0-9]+)[\\.\\,\\s/]+([0-9]+)$': '\\g<1>.\\g<2>', # decimals with multiple decimal point like characters\n",
    "            r'^([0-9]+)[\\.\\,\\s/]+$': '\\g<1>', # decimals with multiple decimal point like characters\n",
    "            r'^[^0-9]+([0-9]+)$': '\\g<1>', # letters followed by integer\n",
    "            r'^[^0-9]+$': ''} # no numbers in expression\n",
    "\n",
    "\n",
    "# regex to determine if a number is in imperial units\n",
    "pattern_height_imperial = r'|'.join(patterns_height_imperial.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ac01142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column to store the cleaned values\n",
    "heights.loc[:, 'observation_value_cleaned'] = heights.loc[:, 'observation_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d3a832db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of non-numeric ones\n",
    "heights['observation_value_cleaned'].apply(lambda v: is_numeric(v) == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fbfcd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to non-numeric values\n",
    "non_numeric1 = heights[heights['observation_value'].apply(lambda v: is_numeric(v) == False)]\n",
    "\n",
    "# clean the first set of non-numeric: lowercase, remove additional spaces, \n",
    "non_numeric1.loc[:, 'observation_value_cleaned'] = non_numeric1.loc[:, 'observation_value'].str.lower().str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "for pattern, replacement in patterns_height_metric.items():\n",
    "    non_numeric1.loc[:, 'observation_value_cleaned'] = non_numeric1.loc[:, 'observation_value_cleaned'].str.replace(pattern, \n",
    "                                                                                                             replacement, regex=True)\n",
    "    \n",
    "# update the height values based on the first cleaned set\n",
    "heights.loc[non_numeric1.index, 'observation_value_cleaned'] = non_numeric1.loc[:, 'observation_value_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4081dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many are left to clean?\n",
    "heights['observation_value_cleaned'].apply(lambda v: is_numeric(v) == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "57ae55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the second set of non-numeric (based on the values being in imperial)\n",
    "non_numeric2 = heights[heights['observation_value_cleaned'].apply(lambda v: \n",
    "                                                                       is_numeric(v) == False)]\n",
    "\n",
    "non_numeric2.loc[:, 'is_imperial'] = False\n",
    "non_numeric2.loc[:, 'is_imperial'] = non_numeric2['observation_value_cleaned'].str.match(pattern_height_imperial)\n",
    "non_numeric2 = non_numeric2[non_numeric2['is_imperial'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0eead29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the height values with cleaned ones (converted from imperial to metric)\n",
    "heights.loc[non_numeric2.index, 'observation_value_cleaned'] = non_numeric2.loc[:, 'observation_value_cleaned'].apply(lambda v: \n",
    "                                                                                                            convert_imperial(v, patterns_height_imperial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f515303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many left to clean?\n",
    "heights['observation_value_cleaned'].apply(lambda v: is_numeric(v) == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30eb4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the 'kg' ones to HEIGHT values\n",
    "height_is_weight = r'^[0-9]+\\s{0,1}kg$'\n",
    "\n",
    "non_numeric3 = heights[heights['observation_value_cleaned'].apply(lambda v: is_numeric(v) == False)]\n",
    "non_numeric3 = non_numeric3[non_numeric3['observation_value_cleaned'].str.contains(height_is_weight, regex=True)]\n",
    "non_numeric3.loc[:, 'observation_value_cleaned'] = non_numeric3['observation_value_cleaned'].str.replace('kg', '').str.strip()\n",
    "\n",
    "heights.loc[non_numeric3.index, 'observation_value_cleaned'] = non_numeric3['observation_value_cleaned']\n",
    "heights.loc[non_numeric3.index, 'observation_type'] = \"WEIGHT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ca2b432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix remaining values\n",
    "non_numeric4 = heights[heights['observation_value_cleaned'].apply(lambda v: is_numeric(v) == False)]\n",
    "\n",
    "for pattern, replacement in patterns_height.items():\n",
    "    non_numeric4.loc[:, 'observation_value_cleaned'] = non_numeric4.loc[:, 'observation_value_cleaned'].str.replace(pattern, \n",
    "                                                                                                             replacement, regex=True)\n",
    "# update the height values with cleaned ones\n",
    "heights.loc[non_numeric4.index, 'observation_value_cleaned'] = non_numeric4.loc[:, 'observation_value_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82f84951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume the remainder are junk - set to 0\n",
    "non_numeric5 = heights[heights['observation_value_cleaned'].apply(lambda v: is_numeric(v) == False)]\n",
    "heights.loc[non_numeric5.index, 'observation_value_cleaned'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3654327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float \n",
    "heights.loc[:, 'observation_value_cleaned'] = heights['observation_value_cleaned'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a164ac2",
   "metadata": {},
   "source": [
    "## 3. Clean BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "35a8d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into numeric and non-numeric\n",
    "# how many non-numeric?\n",
    "bmis[bmis['observation_value'].apply(lambda v: is_numeric(v) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9bdc4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore these bmis (all of the form \"**.* or similar)\n",
    "bmis_nice = bmis[bmis['observation_value'].apply(lambda v: is_numeric(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ed4d6",
   "metadata": {},
   "source": [
    "## 4. Transform extreme weights\n",
    "\n",
    "- Weights > 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4da387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_large_weights(weight):\n",
    "    \"\"\"\n",
    "    For those weights > 400. Based on inspecting these\n",
    "    likely due to additional factor of 10, 100 or 1000\n",
    "    \"\"\"\n",
    "    if 400 < weight < 3000:\n",
    "        weight_new = weight / 10\n",
    "    elif 3000 < weight < 30000:\n",
    "        weight_new = weight / 100\n",
    "    elif 30000 < weight < 99999:\n",
    "        weight_new = weight / 1000\n",
    "    else:\n",
    "        weight_new = weight\n",
    "    return weight_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a9f6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.loc[:, 'observation_value_cleaned'] = weights.loc[:, 'observation_value_cleaned'].apply(lambda w: correct_large_weights(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6be604f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights['observation_value_cleaned'].agg([np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1af8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan values\n",
    "weights = weights[weights.observation_value_cleaned.isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "449d8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(weights['observation_value_cleaned'].values, [0.01, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ee713",
   "metadata": {},
   "source": [
    "## 5. Transform extreme heights\n",
    "\n",
    "In the following order:\n",
    "\n",
    "- Heights < 2.5\n",
    "- Heights > 300\n",
    "- Heights < 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74aae317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert those that are likely in metres\n",
    "bad_in_metres = heights[heights['observation_value_cleaned'] < 2.5]['observation_value_cleaned']\n",
    "heights.loc[bad_in_metres.index, 'observation_value_cleaned'] = bad_in_metres * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9751f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights['observation_value_cleaned'].agg([np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21f4453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan values\n",
    "heights = heights[heights.observation_value_cleaned.isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb60ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(heights['observation_value_cleaned'].values, \n",
    "            [0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e2c18605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many are greater than 300?\n",
    "(heights['observation_value_cleaned'] > 300).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2e185cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do these look like?\n",
    "heights[heights['observation_value_cleaned'] > 300].sort_values(by=['observation_value_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ff99165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct large height values\n",
    "def correct_large_heights(value):\n",
    "    value = int(value)\n",
    "    if value < 1140:\n",
    "        value_new = value / 10\n",
    "    else:\n",
    "        if (len(str(value)) == 4) & (str(value)[:2] in ['11', '12']):\n",
    "            value_new = ''.join([str(value)[0], str(value)[2:]])\n",
    "        elif (len(str(value)) == 4) & (str(value)[:2] in ['14', '15', '16', '17', '18', '19', '21']):\n",
    "            value_new = value / 10\n",
    "        elif (len(str(value)) == 5) & (str(value)[0] in ['1']):\n",
    "            value_new = value / 100\n",
    "        elif (len(str(value)) == 5) & (str(value)[0] in ['3', '4', '5', '6', '7',' 8',' 9']):\n",
    "            value_new = value / 1000\n",
    "        else:\n",
    "            value_new = value\n",
    "    return value_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "008171a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights['observation_value_cleaned'] = heights['observation_value_cleaned'].astype(float)\n",
    "\n",
    "extreme_values = heights[heights['observation_value_cleaned'] > 300].index\n",
    "heights.loc[extreme_values, 'observation_value_cleaned'] = heights.loc[extreme_values, 'observation_value_cleaned'].apply(lambda v: correct_large_heights(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dcbc7",
   "metadata": {},
   "source": [
    "## 6. Transform extreme BMI values\n",
    "\n",
    "- Those less than 5 or greater than 60\n",
    "- *This is currently not used*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02bfc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_values = bmis_nice['observation_value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "48089146",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_values.agg([np.min, np.max, np.median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52f63218",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(bmi_values, [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "586f5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many extreme? < 15 or greater than 60?\n",
    "bmi_small = bmi_values[(bmi_values < 15)]\n",
    "bmi_large = bmi_values[(bmi_values > 70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1a53af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_large.shape[0], bmi_small.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a3f6cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmis_nice['observation_value_cleaned'] = bmis_nice['observation_value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9e17a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights['observation_value_cleaned'] = heights['observation_value_cleaned'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8030de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many small heights are there?\n",
    "(heights['observation_value_cleaned'] < 140).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb71015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi_nice = pd.concat([heights, weights, bmis_nice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49865e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi_nice['observation_value_cleaned'] = hwbmi_nice['observation_value_cleaned'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d900e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi_nice = hwbmi_nice.sort_values(by=['usi', 'observation_dte', 'observation_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fa5ce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi_nice.query('observation_type == \"HEIGHT\"')['observation_value_cleaned'].agg([np.min, np.max, np.median, np.mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ade4f",
   "metadata": {},
   "source": [
    "## 7. Correct interchanged heights and weights\n",
    "\n",
    "Height corrections for those < 140cm\n",
    "\n",
    "1. if two heights on same day, with BMI and weight also reported\n",
    "    - Calculate BMI for each height, keep one closest to reported BMI\n",
    "2. weight > 30, no sensible BMI\n",
    "    - calculate BMI from height, weight. If > 60, remove\n",
    "3. height and weight same day, no BMI\n",
    "    - calculate BMI, if outside (15, 60) swap height and weight\n",
    "4. At least 2 heights, 2 weights same day, with BMI\n",
    "    - calculate BMI for each pair. Swap if outside (15, 60). Then keep pair closest to reported BMI\n",
    "6. weight low but no height reported. \n",
    "    - calculate median height and weight over set of observations. Calculate BMI for this weight as a weight and height. If reasonable as height then rename as height.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1555b1",
   "metadata": {},
   "source": [
    "### Cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f856b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bmi(weight, height):\n",
    "    bmi = weight / (height**2)\n",
    "    return bmi\n",
    "\n",
    "\n",
    "def hw_candidates(height, weight):\n",
    "    \"\"\"\n",
    "    Checks that values likely correspond to a pair of heights and weights\n",
    "    \"\"\"\n",
    "    if (height >= 100) & (weight >= 30):\n",
    "        return True\n",
    "    elif (height > 30) & (weight >= 100):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fed3ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_weight_comparison_same_day(observation_day):\n",
    "    \"\"\"\n",
    "    Compare the heights and weights for a given patient on the same day\n",
    "    Handles the case where there is at least one weight and height observation\n",
    "    and BMI is optional\n",
    "    \n",
    "    Args\n",
    "    -----\n",
    "    observation_day (pd.DataFrame): input dataframe for a patient on a particular day\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    obs_final (pd.DataFrame): the cleaned up dataframe\n",
    "    \"\"\"\n",
    "    heights_day = observation_day.query('observation_type == \"HEIGHT\"')\n",
    "    weights_day = observation_day.query('observation_type == \"WEIGHT\"')\n",
    "    bmis_day = observation_day.query('observation_type == \"BMI\"')\n",
    "    \n",
    "    num_heights = heights_day.shape[0]\n",
    "    num_weights = weights_day.shape[0]\n",
    "    num_bmis = bmis_day.shape[0]\n",
    "    \n",
    "    # if there is a BMI use that to compare heights and weights are valid\n",
    "    if (num_heights >= 1) & (num_weights >= 1) & (num_bmis == 1):\n",
    "        bmi_value = bmis_day['observation_value_cleaned'].values[0]\n",
    "        \n",
    "        for n, m in ((num1, num2) for num1 in range(0, num_heights) for num2 in range(0, num_weights)):\n",
    "            heights_temp = heights_day.iloc[n:n+1]\n",
    "            weights_temp = weights_day.iloc[m:m+1]\n",
    "            h_index = heights_temp.index\n",
    "            w_index = weights_temp.index\n",
    "            height_value = heights_temp['observation_value_cleaned'].values[0]\n",
    "            weight_value = weights_temp['observation_value_cleaned'].values[0]\n",
    "            bmi_temp = calculate_bmi(weight_value, height_value / 100)\n",
    "            bmi_rev_temp = calculate_bmi(height_value, weight_value / 100)\n",
    "            \n",
    "            # heights and weights should be plausible\n",
    "            if hw_candidates(height_value, weight_value):\n",
    "                if np.round(bmi_temp) == np.round(bmi_value):\n",
    "                    obs_final = pd.concat([heights_temp, weights_temp, bmis_day])\n",
    "                    break\n",
    "                elif np.round(bmi_rev_temp) == np.round(bmi_value):\n",
    "                    weights_temp.loc[:, 'observation_type'] = \"HEIGHT\"\n",
    "                    heights_temp.loc[:, 'observation_type'] = \"WEIGHT\"\n",
    "                    obs_final = pd.concat([heights_temp, weights_temp, bmis_day])\n",
    "                    break\n",
    "                else:\n",
    "                    obs_final = pd.concat([heights_temp, weights_temp, bmis_day])\n",
    "            else:\n",
    "                obs_final = pd.concat([heights_temp, weights_temp, bmis_day])\n",
    "    \n",
    "    elif (num_heights >= 1) & (num_weights >= 1) & (num_bmis == 0):\n",
    "        for n, m in ((num1, num2) for num1 in range(0, num_heights) for num2 in range(0, num_weights)):\n",
    "            heights_temp = heights_day.iloc[n:n+1]\n",
    "            weights_temp = weights_day.iloc[m:m+1]\n",
    "            h_index = heights_temp.index\n",
    "            w_index = weights_temp.index\n",
    "            height_value = heights_temp['observation_value_cleaned'].values[0]\n",
    "            weight_value = weights_temp['observation_value_cleaned'].values[0]\n",
    "            bmi_temp = calculate_bmi(weight_value, height_value / 100)\n",
    "            bmi_rev_temp = calculate_bmi(height_value, weight_value / 100)\n",
    "            \n",
    "            # heights and weights should be plausible\n",
    "            if hw_candidates(height_value, weight_value):\n",
    "                if 15 < bmi_temp < 60:\n",
    "                    obs_final = pd.concat([heights_temp, weights_temp])\n",
    "                    break\n",
    "                elif 15 < bmi_rev_temp < 60:\n",
    "                    weights_temp.loc[:, 'observation_value_cleaned'] = height_value\n",
    "                    heights_temp.loc[:, 'observation_value_cleaned'] = weight_value\n",
    "                    obs_final = pd.concat([heights_temp, weights_temp])\n",
    "                    break\n",
    "                else:\n",
    "                    obs_final = pd.concat([heights_temp, weights_temp])     \n",
    "            else:\n",
    "                obs_final = pd.concat([heights_temp, weights_temp, bmis_day])\n",
    "    else:\n",
    "        obs_final = pd.concat([heights_day, weights_day, bmis_day])\n",
    "                \n",
    "    return obs_final\n",
    "\n",
    "def height_weight_comparison_same_days(observation_days):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    days = observation_days['observation_dte'].unique()\n",
    "    dfs_temp = []\n",
    "    for day in days:\n",
    "        observation_day = observation_days.query(f'observation_dte == \"{day}\"')\n",
    "        df_temp = height_weight_comparison_same_day(observation_day)\n",
    "        dfs_temp.append(df_temp)\n",
    "    df_final = pd.concat(dfs_temp)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c7d42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_weight_with_height(observation_patient):\n",
    "    \"\"\"\n",
    "    Correct errors in heights and weights across the patient's history\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1. check if weight more likely a height given timeline of observations\n",
    "    heights_patient = observation_patient.query('observation_type==\"HEIGHT\"')\n",
    "    obs_other_patient = observation_patient[observation_patient['observation_type'].isin(['HEIGHT', 'WEIGHT']) == False]\n",
    "    \n",
    "    # only consider those than are >= 120\n",
    "    heights_patient = heights_patient[heights_patient['observation_value_cleaned'] > 120]\n",
    "    height_median_patient = heights_patient['observation_value_cleaned'].median()\n",
    "    \n",
    "    # if weight within 2cm of median height then relabel as height\n",
    "    weights_patient = observation_patient.query('observation_type==\"WEIGHT\"')\n",
    "    weights_bad_patient = weights_patient[(weights_patient['observation_value_cleaned'] <= height_median_patient + 2) & \n",
    "                                          (weights_patient['observation_value_cleaned'] >= height_median_patient - 2)]\n",
    "    \n",
    "    weights_good_patient = weights_patient[weights_patient.index.isin(weights_bad_patient.index) == False]\n",
    "    \n",
    "    weights_bad_patient['observation_type'] = \"HEIGHT\"\n",
    "    obs_final = pd.concat([obs_other_patient, weights_bad_patient, weights_good_patient, heights_patient])\n",
    "    \n",
    "    return obs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2bfdffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.query('usi.isnull() == False')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c452c8a",
   "metadata": {},
   "source": [
    "For each patient:\n",
    "\n",
    "- Same day cases (BMI present or not) -> one height weight observation max per day\n",
    "- All pairs at different dates -> relabel weights and heights if mixed up\n",
    "- Flag dummy patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "950459e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_height_weight_swapped(observations):\n",
    "    \"\"\"\n",
    "    Correct abnormal height and weights values for each of the patients in observations\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    observations (pd.DataFrame): \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    observations_tidy (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_patients = []\n",
    "    \n",
    "    # separate out the null USI values\n",
    "    observations_null_usi = observations.query('usi.isnull()')\n",
    "    observations_not_null_usi = observations.query('usi.isnull() == False')\n",
    "    \n",
    "    usi_values = observations_not_null_usi['usi'].unique()\n",
    "    \n",
    "    for usi in usi_values:\n",
    "        observation_patient = observations_not_null_usi.query(f'usi == \"{usi}\"')\n",
    "        df_temp = height_weight_comparison_same_days(observation_patient)\n",
    "        df_temp = replace_weight_with_height(df_temp)\n",
    "        dfs_patients.append(df_temp)\n",
    "        \n",
    "    df_final = pd.concat(dfs_patients)\n",
    "    df_final = pd.concat([df_final, observations_null_usi])\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe39edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0 values\n",
    "hwbmi_nice = hwbmi_nice.query('observation_value_cleaned > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98b66602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all patients with at least one recording of a height between 0 and 140\n",
    "small_heights_usi = hwbmi_nice.query('observation_type == \"HEIGHT\"').query('observation_value_cleaned < 140')['usi']\n",
    "small_heights = hwbmi_nice[hwbmi_nice['usi'].isin(small_heights_usi)]\n",
    "\n",
    "# those that have heights only within the normal range\n",
    "non_small_heights = hwbmi_nice.iloc[hwbmi_nice.index.isin(small_heights_usi.index) == False, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3204d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_heights['usi'] = small_heights.usi.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7bdfdef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can take a while (> 15 mins)\n",
    "small_heights_corrected = correct_height_weight_swapped(small_heights_temp[small_heights_temp['patientid'].isin(small_heights_patientid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bbcea74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_heights_corrected = small_heights_corrected.sort_values(by=['usi', 'observation_dte'])\n",
    "\n",
    "# concatenate corrected and normal patient id entries\n",
    "hwbmi = pd.concat([small_heights_corrected, non_small_heights]).drop_duplicates()\n",
    "\n",
    "weights_cleaned = hwbmi.query('observation_type == \"WEIGHT\"')\n",
    "heights_cleaned = hwbmi.query('observation_type == \"HEIGHT\"')\n",
    "bmi_cleaned = hwbmi.query('observation_type == \"BMI\"')\n",
    "\n",
    "# only want to have a single observation for a given patient and given observation type at each day\n",
    "heights_deduped = heights_cleaned.groupby(['usi', 'patientid', 'observation_dte', 'observation_type'])['observation_value_cleaned'].median().reset_index()\n",
    "weights_deduped = weights_cleaned.groupby(['usi', 'patientid', 'observation_dte', 'observation_type'])['observation_value_cleaned'].median().reset_index()\n",
    "bmi_deduped = bmi_cleaned.groupby(['usi', 'patientid', 'observation_dte', 'observation_type'])['observation_value_cleaned'].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2fcc60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it back together\n",
    "hwbmi = pd.concat([heights_deduped, \n",
    "                   weights_deduped, \n",
    "                   bmi_deduped]).sort_values(by=['usi', 'observation_dte', 'observation_type']).reset_index().iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b35a7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the patientid\n",
    "hwbmi = hwbmi.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775cc2cb",
   "metadata": {},
   "source": [
    "## 8. Final cleaning\n",
    "\n",
    "- Small weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "334ef89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, clean any small weights\n",
    "# if weight < 15: multiply by 10\n",
    "weights_tiny = hwbmi.query('observation_type == \"WEIGHT\"').query('observation_value_cleaned < 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "73fea2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi.loc[weights_tiny.index, \"observation_value_cleaned\"] = hwbmi.loc[weights_tiny.index, \"observation_value_cleaned\"] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03764ed",
   "metadata": {},
   "source": [
    "## 9. Summary stats\n",
    "\n",
    "What the BMI, height and weight values look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152dadae",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f7c60104",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi.query('observation_type == \"BMI\"')['observation_value_cleaned'].agg([np.min, np.max, np.median, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "708382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(hwbmi.query('observation_type == \"BMI\"')['observation_value_cleaned'], \n",
    "            [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cb1bff09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.boxplot(hwbmi.query('observation_type == \"BMI\"')['observation_value_cleaned'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19fd17",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5cd7e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi.query('observation_type == \"HEIGHT\"')['observation_value_cleaned'].agg([np.min, np.max, np.median, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4a2e44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(hwbmi.query('observation_type == \"HEIGHT\"')['observation_value_cleaned'], \n",
    "            [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d6619cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.boxplot(hwbmi.query('observation_type == \"HEIGHT\"')['observation_value_cleaned'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1547716",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8bf3eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi.query('observation_type == \"WEIGHT\"')['observation_value_cleaned'].agg([np.min, np.max, np.median, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "868d2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = hwbmi.query('observation_type == \"WEIGHT\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3cd1aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(hwbmi.query('observation_type == \"WEIGHT\"')['observation_value_cleaned'], \n",
    "            [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b6b7b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.boxplot(hwbmi.query('observation_type == \"WEIGHT\"')['observation_value_cleaned'])\n",
    "plt.xlabel('weight (kg)')\n",
    "plt.title('Distribution of patient weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffdb120",
   "metadata": {},
   "source": [
    "## 5. Output the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6cfd69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'M:/Working/AL/projects/weight_loss/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c4b0b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwbmi.to_csv(f'{output_folder}/height_weight_observations_cleaned_040123.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
